{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b8f75f",
   "metadata": {},
   "source": [
    "GRU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f86a85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bcac2",
   "metadata": {},
   "source": [
    "Loading Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5657d531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "      <th>src_tokens_word</th>\n",
       "      <th>trg_tokens_word</th>\n",
       "      <th>src_ids</th>\n",
       "      <th>trg_ids</th>\n",
       "      <th>src_ids_word</th>\n",
       "      <th>trg_ids_word</th>\n",
       "      <th>src_len</th>\n",
       "      <th>trg_len</th>\n",
       "      <th>src_len_word</th>\n",
       "      <th>trg_len_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>['▁i', '▁was', '▁hurt', '▁by', '▁tom', '.']</td>\n",
       "      <td>['▁टमले', '▁मलाई', '▁चोट', '▁पुर्यायो', '।']</td>\n",
       "      <td>['▁i', '▁was', '▁hurt', '▁by', '▁tom.']</td>\n",
       "      <td>['▁टमले', '▁मलाई', '▁चोट', '▁पुर्यायो।']</td>\n",
       "      <td>[2, 8, 74, 1033, 269, 22, 4, 3]</td>\n",
       "      <td>[2, 52, 49, 1724, 2780, 4, 3]</td>\n",
       "      <td>[2, 4, 19, 533, 82, 63, 3]</td>\n",
       "      <td>[2, 8, 6, 681, 1128, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>['▁he', '▁drank', '▁beer', '.']</td>\n",
       "      <td>['▁उनले', '▁बियर', '▁पि', 'ए', '▁', '।']</td>\n",
       "      <td>['▁he', '▁drank', '▁beer.']</td>\n",
       "      <td>['▁उनले', '▁बियर', '▁पिए', '▁।']</td>\n",
       "      <td>[2, 46, 2258, 1270, 4, 3]</td>\n",
       "      <td>[2, 868, 685, 247, 2955, 2926, 4, 3]</td>\n",
       "      <td>[2, 18, 1133, 968, 3]</td>\n",
       "      <td>[2, 253, 243, 2427, 14, 3]</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      src_tokens  \\\n",
       "447  ['▁i', '▁was', '▁hurt', '▁by', '▁tom', '.']   \n",
       "145              ['▁he', '▁drank', '▁beer', '.']   \n",
       "\n",
       "                                       trg_tokens  \\\n",
       "447  ['▁टमले', '▁मलाई', '▁चोट', '▁पुर्यायो', '।']   \n",
       "145      ['▁उनले', '▁बियर', '▁पि', 'ए', '▁', '।']   \n",
       "\n",
       "                             src_tokens_word  \\\n",
       "447  ['▁i', '▁was', '▁hurt', '▁by', '▁tom.']   \n",
       "145              ['▁he', '▁drank', '▁beer.']   \n",
       "\n",
       "                              trg_tokens_word  \\\n",
       "447  ['▁टमले', '▁मलाई', '▁चोट', '▁पुर्यायो।']   \n",
       "145          ['▁उनले', '▁बियर', '▁पिए', '▁।']   \n",
       "\n",
       "                             src_ids                               trg_ids  \\\n",
       "447  [2, 8, 74, 1033, 269, 22, 4, 3]         [2, 52, 49, 1724, 2780, 4, 3]   \n",
       "145        [2, 46, 2258, 1270, 4, 3]  [2, 868, 685, 247, 2955, 2926, 4, 3]   \n",
       "\n",
       "                   src_ids_word                trg_ids_word  src_len  trg_len  \\\n",
       "447  [2, 4, 19, 533, 82, 63, 3]     [2, 8, 6, 681, 1128, 3]        8        7   \n",
       "145       [2, 18, 1133, 968, 3]  [2, 253, 243, 2427, 14, 3]        6        8   \n",
       "\n",
       "     src_len_word  trg_len_word  \n",
       "447             7             6  \n",
       "145             5             6  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading cleaned dataset\n",
    "df = pd.read_csv(\"../data/processed/cleaned_dataset_eng_npi.csv\")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17058e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2689, 12)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of lists into actual lists\n",
    "import ast\n",
    "df[\"src_ids\"] = df[\"src_ids\"].apply(ast.literal_eval)\n",
    "df[\"trg_ids\"] = df[\"trg_ids\"].apply(ast.literal_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f72dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to lists\n",
    "src_data = df[\"src_ids\"].tolist()\n",
    "trg_data = df[\"trg_ids\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and validation (e.g., 90% train, 10% validation)\n",
    "src_train, src_val, trg_train, trg_val = train_test_split(src_data, trg_data, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b88386ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420, 269, 2420, 269)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_train), len(src_val), len(trg_train), len(trg_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b6c3fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b854a9",
   "metadata": {},
   "source": [
    "Creating Datasets and Dataloader using pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ef09471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f2227119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_data[idx], dtype=torch.long), torch.tensor(self.trg_data[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ee969fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function to pad sequences\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "    return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d025a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = TranslationDataset(src_train, trg_train)\n",
    "val_dataset = TranslationDataset(src_val, trg_val)\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d7d4a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from encoder_rnn import Encoder \n",
    "from decoder_rnn import Decoder\n",
    "from seq2seq_rnn import Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b3dbea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n",
      "90100\n",
      "CUDA available: True\n",
      "Device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c4df5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bad8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "105aeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for installing PyTorch with CUDA 11.8 support to ensure compatibility with the GPU\n",
    "\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86900566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define parameters\n",
    "INPUT_DIM = 4000   # size of src vocab\n",
    "OUTPUT_DIM = 4000  # size of trg vocab\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "\n",
    "\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HIDDEN_DIM).to(device)\n",
    "\n",
    "# Initialize Seq2Seq models\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # 0 = padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673e7ff",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d373dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for src, trg in progress_bar:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8158943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1350159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a40c88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|▋         | 1/15 [00:04<00:58,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 5.9219 | Val Loss: 5.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|█▎        | 2/15 [00:08<00:52,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 | Train Loss: 5.1054 | Val Loss: 5.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 3/15 [00:11<00:44,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 | Train Loss: 4.7497 | Val Loss: 5.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  27%|██▋       | 4/15 [00:14<00:39,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 | Train Loss: 4.4164 | Val Loss: 5.1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 5/15 [00:19<00:38,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 | Train Loss: 4.1272 | Val Loss: 5.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 6/15 [00:22<00:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 | Train Loss: 3.8313 | Val Loss: 5.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  47%|████▋     | 7/15 [00:25<00:28,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 | Train Loss: 3.5651 | Val Loss: 5.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|█████▎    | 8/15 [00:29<00:24,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 | Train Loss: 3.3277 | Val Loss: 5.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 9/15 [00:32<00:20,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 | Train Loss: 3.0755 | Val Loss: 5.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|██████▋   | 10/15 [00:35<00:16,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 | Train Loss: 2.8181 | Val Loss: 5.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|███████▎  | 11/15 [00:38<00:13,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 | Train Loss: 2.5926 | Val Loss: 5.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 12/15 [00:42<00:09,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 | Train Loss: 2.3460 | Val Loss: 5.1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  87%|████████▋ | 13/15 [00:45<00:06,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 | Train Loss: 2.1133 | Val Loss: 5.1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|█████████▎| 14/15 [00:48<00:03,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 | Train Loss: 1.9015 | Val Loss: 5.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 15/15 [00:52<00:00,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 | Train Loss: 1.6928 | Val Loss: 5.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N_EPOCHS = 15\n",
    "for epoch in trange(N_EPOCHS, desc=\"Epochs\"):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1922a",
   "metadata": {},
   "source": [
    "Model Saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'seq2seq_gru_eng_npi_model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c2c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
