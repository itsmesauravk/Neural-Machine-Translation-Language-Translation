{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aec727b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sentencepiece as spm\n",
    "from encoder_rnn import Encoder\n",
    "from decoder_rnn import Decoder\n",
    "from seq2seq_rnn import Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e4d03d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en_w = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"../data/processed/spm_eng_n.model\")\n",
    "sp_en_w.load(\"../data/processed/spm_eng_word.model\") \n",
    "\n",
    "sp_npi = spm.SentencePieceProcessor()\n",
    "sp_npi_w = spm.SentencePieceProcessor()\n",
    "sp_npi.load(\"../data/processed/spm_npi_e.model\")\n",
    "sp_npi_w.load(\"../data/processed/spm_npi_word.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "209eb5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3fd6a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = 3000\n",
    "# OUTPUT_DIM =3000\n",
    "# ENC_EMB_DIM = 128\n",
    "# DEC_EMB_DIM = 128\n",
    "# HID_DIM = 256\n",
    "\n",
    "# Define parameters\n",
    "INPUT_DIM = 4000   # size of src vocab\n",
    "OUTPUT_DIM = 4000  # size of trg vocab\n",
    "INPUT_DIM_WORD = 3200   # size of src vocab for word-level\n",
    "OUTPUT_DIM_WORD = 3200  # size of trg vocab for word-level\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HIDDEN_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "612d0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HIDDEN_DIM)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HIDDEN_DIM)\n",
    "# For word-level models\n",
    "encoder_w = Encoder(INPUT_DIM_WORD, ENC_EMB_DIM, HIDDEN_DIM)\n",
    "decoder_w = Decoder(OUTPUT_DIM_WORD, DEC_EMB_DIM, HIDDEN_DIM)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model2 = Seq2Seq(encoder_w, decoder_w, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3cf9b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4000, 256)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (rnn): GRU(256, 512, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4000, 256)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (rnn): GRU(256, 512, batch_first=True)\n",
       "    (fc_out): Linear(in_features=512, out_features=4000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"seq2seq_gru_eng_npi_model.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "03b518dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(3200, 256)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (rnn): GRU(256, 512, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(3200, 256)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (rnn): GRU(256, 512, batch_first=True)\n",
       "    (fc_out): Linear(in_features=512, out_features=3200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(\"seq2seq_gru_eng_npi_model_word.pt\", map_location=device))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0773a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, sp_en, sp_de, device, max_len=20):\n",
    "    model.eval()\n",
    "    tokens = sp_en.encode(sentence, out_type=int)\n",
    "    tokens = [2] + tokens + [3]  # BOS and EOS tokens\n",
    "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)  # batch_size=1, seq_len=...\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "\n",
    "    trg_indexes = [2]  # BOS token\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "            pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == 3:  # EOS token\n",
    "            break\n",
    "\n",
    "    translated_text = sp_de.decode(trg_indexes[1:-1])  # remove BOS and EOS\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3b509001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Today is my birthday\n",
      "Nepali: मेरो जन्मदिन मेरो नाम हो।\n"
     ]
    }
   ],
   "source": [
    "english_sentence = \"Today is my birthday\"\n",
    "\n",
    "try:\n",
    "    translation = translate_sentence(english_sentence, model, sp_en, sp_npi, device)\n",
    "    print(\"English:\", english_sentence)\n",
    "    print(\"Nepali:\", translation)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error during translation:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ac0ba",
   "metadata": {},
   "source": [
    "BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87ba288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecff120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Saurav\n",
      "[nltk_data]     Karki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dae4270c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Nepali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who?</td>\n",
       "      <td>को?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुकाउनुहोस्।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुक।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay.</td>\n",
       "      <td>बस्नुहोस्।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>नमस्ते!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English        Nepali\n",
       "0    Who?           को?\n",
       "1   Hide.  लुकाउनुहोस्।\n",
       "2   Hide.          लुक।\n",
       "3   Stay.    बस्नुहोस्।\n",
       "4  Hello!       नमस्ते!"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your file\n",
    "file_path = \"../data/raw/npi-eng/npi.txt\"\n",
    "\n",
    "# Read the file, split by tabs, and keep only the first two columns (English and German)\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", header=None, usecols=[0,1], names=[\"English\", \"Nepali\"])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "21745d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Nepali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A friend lent me that book.</td>\n",
       "      <td>त्यो किताब साथिबाट उधारो पाएको हो।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What color is the roof of your house?</td>\n",
       "      <td>तपाईको घरको छानो कस्तो रङको छ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was very upset.</td>\n",
       "      <td>म निकै उदास थिएँ ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went sightseeing.</td>\n",
       "      <td>म घुम्न गएँ ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japan began to import rice from the United Sta...</td>\n",
       "      <td>जापानले अमेरिकाबाट चामल आयात गर्न थाल्यो।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                        A friend lent me that book.   \n",
       "1              What color is the roof of your house?   \n",
       "2                                  I was very upset.   \n",
       "3                                I went sightseeing.   \n",
       "4  Japan began to import rice from the United Sta...   \n",
       "\n",
       "                                      Nepali  \n",
       "0         त्यो किताब साथिबाट उधारो पाएको हो।  \n",
       "1             तपाईको घरको छानो कस्तो रङको छ?  \n",
       "2                         म निकै उदास थिएँ ।  \n",
       "3                              म घुम्न गएँ ।  \n",
       "4  जापानले अमेरिकाबाट चामल आयात गर्न थाल्यो।  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.sample(500, random_state=42)  # Randomly sample 500 rows\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e99331db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A friend lent me that book.', 'What color is the roof of your house?', 'I was very upset.']\n",
      "['त्यो किताब साथिबाट उधारो पाएको हो।', 'तपाईको घरको छानो कस्तो रङको छ?', 'म निकै उदास थिएँ ।']\n"
     ]
    }
   ],
   "source": [
    "test_sentences = new_df['English'].tolist()  # list of English sentences (source)\n",
    "reference_sentences = new_df['Nepali'].tolist()  # list of German sentences (reference)\n",
    "\n",
    "print(test_sentences[:3])\n",
    "\n",
    "print(reference_sentences[:3])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6235a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentences(sentences, model, sp_en, sp_de, device):\n",
    "    translations = []\n",
    "    for sent in sentences:\n",
    "        # print(f\"Translating: {sent}\")\n",
    "        translation = translate_sentence(sent, model, sp_en, sp_de, device)\n",
    "        # print(f\"Translation: {translation}\")\n",
    "        translations.append(translation)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1bbee3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A friend lent me that book.',\n",
       " 'What color is the roof of your house?',\n",
       " 'I was very upset.']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = new_df['English'].tolist()  # list of English sentences (source)\n",
    "input_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "248f788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['त्यो किताब साथिबाट उधारो पाएको हो।'], ['तपाईको घरको छानो कस्तो रङको छ?'], ['म निकै उदास थिएँ ।']]\n"
     ]
    }
   ],
   "source": [
    "#making References\n",
    "# Original list\n",
    "refs = new_df['Nepali'].tolist()\n",
    "\n",
    "# Convert to list of lists (each inner list with one reference string)\n",
    "references = [[ref] for ref in refs]\n",
    "\n",
    "print(references[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c60491d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates: ['हामीले मलाई गर्न सजिलो त्यो गर्न दिनुहोस्।', 'संसारको सबैभन्दा अग्लो कति छ?', 'धेरै धेरै धेरै आए।']\n"
     ]
    }
   ],
   "source": [
    "# candidates are model translations\n",
    "\n",
    "candidates = translate_sentences(input_data, model, sp_en, sp_npi, device)\n",
    "print(\"Candidates:\", candidates[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcfcf4",
   "metadata": {},
   "source": [
    "### **BLEU, METEOR, and chrF (with NLTK and SacreBLEU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9951db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ad518858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sacrebleu.metrics import CHRF\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize (basic whitespace tokenization)\n",
    "tokenized_refs = [[ref.split() for ref in refs] for refs in references]\n",
    "tokenized_cands = [cand.split() for cand in candidates]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66cc665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram BLEU score: 0.1262\n",
      "2-gram BLEU score: 0.0612\n",
      "3-gram BLEU score: 0.0431\n",
      "4-gram BLEU score: 0.0319\n"
     ]
    }
   ],
   "source": [
    "# 1. BLEU Score\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "\n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "# Calculate BLEU with weights to only consider 1-gram\n",
    "bleu_1gram = corpus_bleu(references, candidates, weights=(1, 0, 0, 0) , smoothing_function=smooth)\n",
    "bleu_2gram = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0, 0), smoothing_function=smooth)\n",
    "bleu_3gram = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smooth)\n",
    "bleu_4gram = corpus_bleu(references, candidates, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth)\n",
    "\n",
    "print(f\"1-gram BLEU score: {bleu_1gram:.4f}\")\n",
    "print(f\"2-gram BLEU score: {bleu_2gram:.4f}\")\n",
    "print(f\"3-gram BLEU score: {bleu_3gram:.4f}\")\n",
    "print(f\"4-gram BLEU score: {bleu_4gram:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "184b31f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHRF SCORE: 45.0758\n"
     ]
    }
   ],
   "source": [
    "# 2. CHRF Score\n",
    "\n",
    "from sacrebleu.metrics import CHRF\n",
    "\n",
    "\n",
    "chrf_metric = CHRF()\n",
    "chrf_score = chrf_metric.corpus_score(candidates, references)\n",
    "print(f\"CHRF SCORE: {chrf_score.score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61788e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
