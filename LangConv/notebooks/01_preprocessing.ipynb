{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92cff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHorizon\n"
     ]
    }
   ],
   "source": [
    "print(\"EHorizon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457d2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw/deu-eng/deu.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9240a",
   "metadata": {},
   "source": [
    "Data is collected from manything.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fd6137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
      "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
      "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
      "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
      "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n"
     ]
    }
   ],
   "source": [
    "#reading .txt file\n",
    "with open(DATA_PATH, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# View the first 5 lines\n",
    "for line in lines[:5]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65271dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing metadata tags from data\n",
    "cleaned_pairs = []\n",
    "with open(DATA_PATH, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 2:  # Ensure at least English and German\n",
    "            english = parts[0].strip()\n",
    "            german = parts[1].strip()\n",
    "            cleaned_pairs.append([english, german])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89133d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go.', 'Geh.'],\n",
       " ['Hi.', 'Hallo!'],\n",
       " ['Hi.', 'Grüß Gott!'],\n",
       " ['Run!', 'Lauf!'],\n",
       " ['Run.', 'Lauf!']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "509175d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277891"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f2deb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Geh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hallo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Grüß Gott!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lauf!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Lauf!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English      German\n",
       "0     Go.        Geh.\n",
       "1     Hi.      Hallo!\n",
       "2     Hi.  Grüß Gott!\n",
       "3    Run!       Lauf!\n",
       "4    Run.       Lauf!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(cleaned_pairs, columns=['English', 'German'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa48fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n",
      "English    0\n",
      "German     0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#basic cleaning\n",
    "null_values = df.isnull().sum()\n",
    "duplicate_values = df.duplicated().sum()\n",
    "\n",
    "print(\"Null Values:\")\n",
    "print(null_values)\n",
    "print(\"\\nDuplicate Values:\")\n",
    "print(duplicate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9d573c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in d:\\ai projects\\langconv\\venv\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in d:\\ai projects\\langconv\\venv\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in d:\\ai projects\\langconv\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in d:\\ai projects\\langconv\\venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'D:\\AI Projects\\LangConv\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5ae03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aa536eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contractions example :  Hello, how are you? You are amazing! Do not go!!! \n",
      "Lowercase example :  hello, how are you? you are amazing! do not go!!! \n",
      "Punctuation example :  hello how are you? you are amazing! do not go!!! \n",
      "Whitespace example :  hello how are you? you are amazing! do not go!!!\n"
     ]
    }
   ],
   "source": [
    "#example of raw text cleaning\n",
    "sample_text = \"Hello, how are you? You're amazing! Don't go!!! \"\n",
    "sample_text = contractions.fix(sample_text)\n",
    "print(\"Contractions example : \",sample_text)\n",
    "sample_text = sample_text.lower()\n",
    "print(\"Lowercase example : \", sample_text)\n",
    "exclude = ''.join(ch for ch in string.punctuation if ch not in ['?', '.', '!'])\n",
    "sample_text = re.sub(rf\"[{re.escape(exclude)}]\", \"\", sample_text)\n",
    "print(\"Punctuation example : \",sample_text)\n",
    "sample_text =  re.sub(r\"\\s+\", \" \", sample_text).strip()\n",
    "print(\"Whitespace example : \", sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "678db794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lowercase=True, remove_punct=True, expand_contr=True):\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "    if expand_contr:\n",
    "        text = contractions.fix(text)\n",
    "\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    if remove_punct:\n",
    "        exclude = ''.join(ch for ch in string.punctuation if ch not in ['?', '.', '!'])\n",
    "        text = re.sub(rf\"[{re.escape(exclude)}]\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a234f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to English column\n",
    "df['English_clean'] = df['English'].apply(\n",
    "    lambda x: clean_text(x, lowercase=True, remove_punct=True, expand_contr=True)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to German column (no contractions expansion for German)\n",
    "df['German_clean'] = df['German'].apply(\n",
    "    lambda x: clean_text(x, lowercase=True, remove_punct=True, expand_contr=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cd6d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping original columns\n",
    "df.drop(columns=['English', 'German'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b498de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_clean</th>\n",
       "      <th>German_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91534</th>\n",
       "      <td>i am very happy in boston.</td>\n",
       "      <td>ich bin sehr glücklich in boston.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257412</th>\n",
       "      <td>you should not laugh at tom when he makes mist...</td>\n",
       "      <td>du darfst nicht über tom lachen wenn er einen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125732</th>\n",
       "      <td>there is not anyone in there.</td>\n",
       "      <td>da ist niemand.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74246</th>\n",
       "      <td>tom put his glasses on.</td>\n",
       "      <td>tom setzte sich die brille auf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49191</th>\n",
       "      <td>his mother was right.</td>\n",
       "      <td>seine mutter hatte recht.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            English_clean  \\\n",
       "91534                          i am very happy in boston.   \n",
       "257412  you should not laugh at tom when he makes mist...   \n",
       "125732                      there is not anyone in there.   \n",
       "74246                             tom put his glasses on.   \n",
       "49191                               his mother was right.   \n",
       "\n",
       "                                             German_clean  \n",
       "91534                   ich bin sehr glücklich in boston.  \n",
       "257412  du darfst nicht über tom lachen wenn er einen ...  \n",
       "125732                                    da ist niemand.  \n",
       "74246                     tom setzte sich die brille auf.  \n",
       "49191                           seine mutter hatte recht.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fc9c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save source (e.g., English)\n",
    "df['English_clean'].to_csv('../data/processed/src_train.txt', index=False, header=False)\n",
    "\n",
    "# Save target (e.g., German)\n",
    "df['German_clean'].to_csv('../data/processed/trg_train.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6f539",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e93016",
   "metadata": {},
   "source": [
    "I am using SentencePiece Tokenizer using  Byte Pair Encoding (BPE) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c95171b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in d:\\ai projects\\langconv\\venv\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'D:\\AI Projects\\LangConv\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8f889df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c5bd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English tokenizer\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='../data/processed/src_train.txt',\n",
    "    model_prefix='../data/processed/spm_en',\n",
    "    vocab_size=16000,\n",
    "    model_type='bpe',\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3,\n",
    "    user_defined_symbols=[\".\", \"!\", \"?\"]\n",
    ")\n",
    "\n",
    "# German tokenizer\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='../data/processed/trg_train.txt',\n",
    "    model_prefix='../data/processed/spm_de',\n",
    "    vocab_size=16000,\n",
    "    model_type='bpe',\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3,\n",
    "    user_defined_symbols=[\".\", \"!\", \"?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7beaaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading trained Tokenization models\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.load('../data/processed/spm_en.model')\n",
    "\n",
    "sp_de = spm.SentencePieceProcessor()\n",
    "sp_de.load('../data/processed/spm_de.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "393978b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Tokens: ['▁', 'H', 'ell', 'o', ',', '▁how', '▁are', '▁you', '?', '▁', 'Y', 'ou', \"'\", 're', '▁amazing', '!', '▁', 'D', 'on', \"'\", 't', '▁go', '!', '!', '!']\n",
      "German Tokens: ['▁', 'H', 'all', 'o', ',', '▁wie', '▁geht', '▁es', '▁dir', '?', '▁', 'D', 'u', '▁bist', '▁erstaunlich', '!', '▁', 'G', 'eh', '▁nicht', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "sample_text_en = \"Hello, how are you? You're amazing! Don't go!!!\"\n",
    "sample_text_de = \"Hallo, wie geht es dir? Du bist erstaunlich! Geh nicht!!!\"\n",
    "\n",
    "# Tokenizing sample text\n",
    "tokens_en = sp_en.encode(sample_text_en, out_type=str)\n",
    "tokens_de = sp_de.encode(sample_text_de, out_type=str)\n",
    "\n",
    "print(\"English Tokens:\", tokens_en)\n",
    "print(\"German Tokens:\", tokens_de)\n",
    "\n",
    "# Detokenizing sample text\n",
    "# detokenized_en = sp_en.decode(tokens_en)\n",
    "# detokenized_de = sp_de.decode(tokens_de)\n",
    "# print(\"Detokenized English:\", detokenized_en)\n",
    "# print(\"Detokenized German:\", detokenized_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eee472f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the DataFrame with tokenized columns\n",
    "df['src_tokens'] = df['English_clean'].apply(lambda x: sp_en.encode(x, out_type=str))\n",
    "df['trg_tokens'] = df['German_clean'].apply(lambda x: sp_de.encode(x, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d54e2473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_clean</th>\n",
       "      <th>German_clean</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197206</th>\n",
       "      <td>she accused him of stealing her car.</td>\n",
       "      <td>sie beschuldigte ihn ihr auto gestohlen zu haben.</td>\n",
       "      <td>[▁she, ▁accused, ▁him, ▁of, ▁stealing, ▁her, ▁...</td>\n",
       "      <td>[▁sie, ▁beschuldigte, ▁ihn, ▁ihr, ▁auto, ▁gest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95218</th>\n",
       "      <td>tom likes playing soccer.</td>\n",
       "      <td>tom spielt gerne fußball.</td>\n",
       "      <td>[▁tom, ▁likes, ▁playing, ▁soccer, .]</td>\n",
       "      <td>[▁tom, ▁spielt, ▁gerne, ▁fußball, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24596</th>\n",
       "      <td>go get some water.</td>\n",
       "      <td>geh etwas wasser holen.</td>\n",
       "      <td>[▁go, ▁get, ▁some, ▁water, .]</td>\n",
       "      <td>[▁geh, ▁etwas, ▁wasser, ▁holen, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206833</th>\n",
       "      <td>where have you been? i have been worried.</td>\n",
       "      <td>wo sind sie gewesen? ich habe mir sorgen gemacht.</td>\n",
       "      <td>[▁where, ▁have, ▁you, ▁been, ?, ▁i, ▁have, ▁be...</td>\n",
       "      <td>[▁wo, ▁sind, ▁sie, ▁gewesen, ?, ▁ich, ▁habe, ▁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126823</th>\n",
       "      <td>tom is an aggressive driver.</td>\n",
       "      <td>tom ist ein aggressiver autofahrer.</td>\n",
       "      <td>[▁tom, ▁is, ▁an, ▁aggressive, ▁driver, .]</td>\n",
       "      <td>[▁tom, ▁ist, ▁ein, ▁aggress, iver, ▁autofahrer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    English_clean  \\\n",
       "197206       she accused him of stealing her car.   \n",
       "95218                   tom likes playing soccer.   \n",
       "24596                          go get some water.   \n",
       "206833  where have you been? i have been worried.   \n",
       "126823               tom is an aggressive driver.   \n",
       "\n",
       "                                             German_clean  \\\n",
       "197206  sie beschuldigte ihn ihr auto gestohlen zu haben.   \n",
       "95218                           tom spielt gerne fußball.   \n",
       "24596                             geh etwas wasser holen.   \n",
       "206833  wo sind sie gewesen? ich habe mir sorgen gemacht.   \n",
       "126823                tom ist ein aggressiver autofahrer.   \n",
       "\n",
       "                                               src_tokens  \\\n",
       "197206  [▁she, ▁accused, ▁him, ▁of, ▁stealing, ▁her, ▁...   \n",
       "95218                [▁tom, ▁likes, ▁playing, ▁soccer, .]   \n",
       "24596                       [▁go, ▁get, ▁some, ▁water, .]   \n",
       "206833  [▁where, ▁have, ▁you, ▁been, ?, ▁i, ▁have, ▁be...   \n",
       "126823          [▁tom, ▁is, ▁an, ▁aggressive, ▁driver, .]   \n",
       "\n",
       "                                               trg_tokens  \n",
       "197206  [▁sie, ▁beschuldigte, ▁ihn, ▁ihr, ▁auto, ▁gest...  \n",
       "95218                [▁tom, ▁spielt, ▁gerne, ▁fußball, .]  \n",
       "24596                  [▁geh, ▁etwas, ▁wasser, ▁holen, .]  \n",
       "206833  [▁wo, ▁sind, ▁sie, ▁gewesen, ?, ▁ich, ▁habe, ▁...  \n",
       "126823  [▁tom, ▁ist, ▁ein, ▁aggress, iver, ▁autofahrer...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3f41248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Source Tokens Length: 105\n",
      "Min Source Tokens Length: 2\n",
      "--------------------------------------------------\n",
      "Max Target Tokens Length: 100\n",
      "Min Target Tokens Length: 2\n",
      "--------------------------------------------------\n",
      "Average Source Tokens Length: 7.6800724024887455\n",
      "Average Target Tokens Length: 7.684754094231192\n"
     ]
    }
   ],
   "source": [
    "#Calculating the average length of tokens in the source and target languages\n",
    "avg_src_length = df['src_tokens'].apply(len).mean()\n",
    "max_src_length = df['src_tokens'].apply(len).max()\n",
    "min_src_length = df['src_tokens'].apply(len).min()\n",
    "\n",
    "avg_trg_length = df['trg_tokens'].apply(len).mean()\n",
    "max_trg_length = df['trg_tokens'].apply(len).max()\n",
    "min_trg_length = df['trg_tokens'].apply(len).min()\n",
    "\n",
    "print(f\"Max Source Tokens Length: {max_src_length}\")\n",
    "print(f\"Min Source Tokens Length: {min_src_length}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Max Target Tokens Length: {max_trg_length}\")\n",
    "print(f\"Min Target Tokens Length: {min_trg_length}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Average Source Tokens Length: {avg_src_length}\")\n",
    "print(f\"Average Target Tokens Length: {avg_trg_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b34676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8caf7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tokens to IDs\n",
    "df['src_ids'] = df['English_clean'].apply(lambda s: sp_en.encode(s, out_type=int))\n",
    "df['trg_ids'] = df['German_clean'].apply(lambda s: sp_de.encode(s, out_type=int))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "658b4abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_clean</th>\n",
       "      <th>German_clean</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "      <th>src_ids</th>\n",
       "      <th>trg_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152778</th>\n",
       "      <td>i know that tom is a smart boy.</td>\n",
       "      <td>ich weiß dass tom ein kluger junge ist.</td>\n",
       "      <td>[▁i, ▁know, ▁that, ▁tom, ▁is, ▁a, ▁smart, ▁boy...</td>\n",
       "      <td>[▁ich, ▁weiß, ▁dass, ▁tom, ▁ein, ▁kluger, ▁jun...</td>\n",
       "      <td>[8, 121, 56, 22, 32, 9, 1850, 798, 4]</td>\n",
       "      <td>[27, 212, 88, 28, 41, 8481, 1164, 49, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232253</th>\n",
       "      <td>tom crawled into bed just before midnight.</td>\n",
       "      <td>tom ist erst kurz vor mitternacht ins bett gek...</td>\n",
       "      <td>[▁tom, ▁crawled, ▁into, ▁bed, ▁just, ▁before, ...</td>\n",
       "      <td>[▁tom, ▁ist, ▁erst, ▁kurz, ▁vor, ▁mitternacht,...</td>\n",
       "      <td>[22, 7405, 471, 674, 263, 465, 3032, 4]</td>\n",
       "      <td>[28, 49, 939, 1283, 177, 4021, 567, 919, 564, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120492</th>\n",
       "      <td>he asked for a lot of money.</td>\n",
       "      <td>er forderte viel geld.</td>\n",
       "      <td>[▁he, ▁asked, ▁for, ▁a, ▁lot, ▁of, ▁money, .]</td>\n",
       "      <td>[▁er, ▁forderte, ▁viel, ▁geld, .]</td>\n",
       "      <td>[46, 467, 88, 9, 343, 69, 364, 4]</td>\n",
       "      <td>[57, 6833, 193, 394, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262632</th>\n",
       "      <td>he sent me a letter asking if the book had rea...</td>\n",
       "      <td>er schickte mir einen brief in dem er mich fra...</td>\n",
       "      <td>[▁he, ▁sent, ▁me, ▁a, ▁letter, ▁asking, ▁if, ▁...</td>\n",
       "      <td>[▁er, ▁schickte, ▁mir, ▁einen, ▁brief, ▁in, ▁d...</td>\n",
       "      <td>[46, 1082, 78, 9, 776, 1733, 220, 23, 321, 209...</td>\n",
       "      <td>[57, 4086, 114, 171, 916, 77, 181, 57, 127, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175717</th>\n",
       "      <td>tom knows where to draw the line.</td>\n",
       "      <td>tom weiß wo er einen schlußstrich ziehen muß.</td>\n",
       "      <td>[▁tom, ▁knows, ▁where, ▁to, ▁draw, ▁the, ▁line...</td>\n",
       "      <td>[▁tom, ▁weiß, ▁wo, ▁er, ▁einen, ▁schl, uß, str...</td>\n",
       "      <td>[22, 552, 264, 10, 2021, 23, 2061, 4]</td>\n",
       "      <td>[28, 212, 124, 57, 171, 255, 5768, 15234, 2148...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            English_clean  \\\n",
       "152778                    i know that tom is a smart boy.   \n",
       "232253         tom crawled into bed just before midnight.   \n",
       "120492                       he asked for a lot of money.   \n",
       "262632  he sent me a letter asking if the book had rea...   \n",
       "175717                  tom knows where to draw the line.   \n",
       "\n",
       "                                             German_clean  \\\n",
       "152778            ich weiß dass tom ein kluger junge ist.   \n",
       "232253  tom ist erst kurz vor mitternacht ins bett gek...   \n",
       "120492                             er forderte viel geld.   \n",
       "262632  er schickte mir einen brief in dem er mich fra...   \n",
       "175717      tom weiß wo er einen schlußstrich ziehen muß.   \n",
       "\n",
       "                                               src_tokens  \\\n",
       "152778  [▁i, ▁know, ▁that, ▁tom, ▁is, ▁a, ▁smart, ▁boy...   \n",
       "232253  [▁tom, ▁crawled, ▁into, ▁bed, ▁just, ▁before, ...   \n",
       "120492      [▁he, ▁asked, ▁for, ▁a, ▁lot, ▁of, ▁money, .]   \n",
       "262632  [▁he, ▁sent, ▁me, ▁a, ▁letter, ▁asking, ▁if, ▁...   \n",
       "175717  [▁tom, ▁knows, ▁where, ▁to, ▁draw, ▁the, ▁line...   \n",
       "\n",
       "                                               trg_tokens  \\\n",
       "152778  [▁ich, ▁weiß, ▁dass, ▁tom, ▁ein, ▁kluger, ▁jun...   \n",
       "232253  [▁tom, ▁ist, ▁erst, ▁kurz, ▁vor, ▁mitternacht,...   \n",
       "120492                  [▁er, ▁forderte, ▁viel, ▁geld, .]   \n",
       "262632  [▁er, ▁schickte, ▁mir, ▁einen, ▁brief, ▁in, ▁d...   \n",
       "175717  [▁tom, ▁weiß, ▁wo, ▁er, ▁einen, ▁schl, uß, str...   \n",
       "\n",
       "                                                  src_ids  \\\n",
       "152778              [8, 121, 56, 22, 32, 9, 1850, 798, 4]   \n",
       "232253            [22, 7405, 471, 674, 263, 465, 3032, 4]   \n",
       "120492                  [46, 467, 88, 9, 343, 69, 364, 4]   \n",
       "262632  [46, 1082, 78, 9, 776, 1733, 220, 23, 321, 209...   \n",
       "175717              [22, 552, 264, 10, 2021, 23, 2061, 4]   \n",
       "\n",
       "                                                  trg_ids  \n",
       "152778           [27, 212, 88, 28, 41, 8481, 1164, 49, 4]  \n",
       "232253  [28, 49, 939, 1283, 177, 4021, 567, 919, 564, ...  \n",
       "120492                            [57, 6833, 193, 394, 4]  \n",
       "262632  [57, 4086, 114, 171, 916, 77, 181, 57, 127, 11...  \n",
       "175717  [28, 212, 124, 57, 171, 255, 5768, 15234, 2148...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "416281ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "\n",
    "#drop original columns\n",
    "new_df.drop(columns=['English_clean', 'German_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a834178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS ID for English: 2\n",
      "EOS ID for English: 3\n",
      "BOS ID for German: 2\n",
      "EOS ID for German: 3\n"
     ]
    }
   ],
   "source": [
    "bos_id_en = sp_en.bos_id()   # English BOS, usually 2\n",
    "eos_id_en = sp_en.eos_id()\n",
    "\n",
    "bos_id_de = sp_de.bos_id()   # German BOS, usually 2\n",
    "eos_id_de = sp_de.eos_id()\n",
    "\n",
    "print(\"BOS ID for English:\", bos_id_en)\n",
    "print(\"EOS ID for English:\", eos_id_en)\n",
    "print(\"BOS ID for German:\", bos_id_de)\n",
    "print(\"EOS ID for German:\", eos_id_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4246547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding BOS and EOS tokens to the source and target IDs\n",
    "new_df['src_ids'] = new_df['src_ids'].apply(lambda x: [bos_id_en] + x + [eos_id_en])\n",
    "new_df['trg_ids'] = new_df['trg_ids'].apply(lambda x: [bos_id_de] + x + [eos_id_de])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "511b3243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "      <th>src_ids</th>\n",
       "      <th>trg_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188826</th>\n",
       "      <td>[▁i, ▁will, ▁have, ▁a, ▁coffee, ▁and, ▁a, ▁cro...</td>\n",
       "      <td>[▁ich, ▁nehme, ▁einen, ▁kaffee, ▁und, ▁ein, ▁h...</td>\n",
       "      <td>[2, 8, 102, 65, 9, 746, 130, 9, 15017, 4, 3]</td>\n",
       "      <td>[2, 27, 1866, 171, 867, 140, 41, 416, 3535, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121561</th>\n",
       "      <td>[▁i, ▁do, ▁not, ▁know, ▁how, ▁they, ▁do, ▁it, .]</td>\n",
       "      <td>[▁ich, ▁weiß, ▁nicht, ▁wie, ▁sie, ▁das, ▁mache...</td>\n",
       "      <td>[2, 8, 35, 37, 121, 153, 203, 35, 63, 4, 3]</td>\n",
       "      <td>[2, 27, 212, 44, 108, 54, 38, 315, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212978</th>\n",
       "      <td>[▁what, ▁time, ▁do, ▁you, ▁get, ▁up, ▁on, ▁sch...</td>\n",
       "      <td>[▁um, ▁wieviel, ▁uhr, ▁stehst, ▁du, ▁auf, ▁wen...</td>\n",
       "      <td>[2, 94, 194, 35, 21, 179, 196, 81, 11470, 59, ...</td>\n",
       "      <td>[2, 176, 2402, 626, 5440, 51, 94, 237, 581, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52914</th>\n",
       "      <td>[▁that, ▁is, ▁pretty, ▁normal, .]</td>\n",
       "      <td>[▁das, ▁ist, ▁ganz, ▁normal, .]</td>\n",
       "      <td>[2, 56, 32, 872, 2553, 4, 3]</td>\n",
       "      <td>[2, 38, 49, 356, 1647, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186386</th>\n",
       "      <td>[▁chocolate, ▁ice, ▁cream, ▁is, ▁my, ▁favorite...</td>\n",
       "      <td>[▁schokoladeneis, ▁esse, ▁ich, ▁am, ▁allerlieb...</td>\n",
       "      <td>[2, 2268, 1527, 2125, 32, 99, 1017, 4, 3]</td>\n",
       "      <td>[2, 10897, 1865, 27, 297, 10882, 4, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               src_tokens  \\\n",
       "188826  [▁i, ▁will, ▁have, ▁a, ▁coffee, ▁and, ▁a, ▁cro...   \n",
       "121561   [▁i, ▁do, ▁not, ▁know, ▁how, ▁they, ▁do, ▁it, .]   \n",
       "212978  [▁what, ▁time, ▁do, ▁you, ▁get, ▁up, ▁on, ▁sch...   \n",
       "52914                   [▁that, ▁is, ▁pretty, ▁normal, .]   \n",
       "186386  [▁chocolate, ▁ice, ▁cream, ▁is, ▁my, ▁favorite...   \n",
       "\n",
       "                                               trg_tokens  \\\n",
       "188826  [▁ich, ▁nehme, ▁einen, ▁kaffee, ▁und, ▁ein, ▁h...   \n",
       "121561  [▁ich, ▁weiß, ▁nicht, ▁wie, ▁sie, ▁das, ▁mache...   \n",
       "212978  [▁um, ▁wieviel, ▁uhr, ▁stehst, ▁du, ▁auf, ▁wen...   \n",
       "52914                     [▁das, ▁ist, ▁ganz, ▁normal, .]   \n",
       "186386  [▁schokoladeneis, ▁esse, ▁ich, ▁am, ▁allerlieb...   \n",
       "\n",
       "                                                  src_ids  \\\n",
       "188826       [2, 8, 102, 65, 9, 746, 130, 9, 15017, 4, 3]   \n",
       "121561        [2, 8, 35, 37, 121, 153, 203, 35, 63, 4, 3]   \n",
       "212978  [2, 94, 194, 35, 21, 179, 196, 81, 11470, 59, ...   \n",
       "52914                        [2, 56, 32, 872, 2553, 4, 3]   \n",
       "186386          [2, 2268, 1527, 2125, 32, 99, 1017, 4, 3]   \n",
       "\n",
       "                                                  trg_ids  \n",
       "188826  [2, 27, 1866, 171, 867, 140, 41, 416, 3535, 4, 3]  \n",
       "121561           [2, 27, 212, 44, 108, 54, 38, 315, 4, 3]  \n",
       "212978  [2, 176, 2402, 626, 5440, 51, 94, 237, 581, 49...  \n",
       "52914                        [2, 38, 49, 356, 1647, 4, 3]  \n",
       "186386             [2, 10897, 1865, 27, 297, 10882, 4, 3]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4b90d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['src_len'] = new_df['src_ids'].apply(len)\n",
    "new_df['trg_len'] = new_df['trg_ids'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b02a832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "      <th>src_ids</th>\n",
       "      <th>trg_ids</th>\n",
       "      <th>src_len</th>\n",
       "      <th>trg_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125301</th>\n",
       "      <td>[▁that, ▁is, ▁why, ▁i, ▁do, ▁not, ▁like, ▁tom, .]</td>\n",
       "      <td>[▁deshalb, ▁mag, ▁ich, ▁tom, ▁nicht, .]</td>\n",
       "      <td>[2, 56, 32, 193, 8, 35, 37, 133, 22, 4, 3]</td>\n",
       "      <td>[2, 3252, 403, 27, 28, 44, 4, 3]</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163846</th>\n",
       "      <td>[▁let, ▁us, ▁start, ▁as, ▁soon, ▁as, ▁he, ▁com...</td>\n",
       "      <td>[▁lasst, ▁uns, ▁beginnen, ▁sobald, ▁er, ▁kommt...</td>\n",
       "      <td>[2, 254, 149, 551, 127, 570, 127, 46, 1382, 4, 3]</td>\n",
       "      <td>[2, 1410, 166, 3527, 2530, 57, 569, 4, 3]</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127910</th>\n",
       "      <td>[▁tom, ▁wondered, ▁the, ▁same, ▁thing, .]</td>\n",
       "      <td>[▁tom, ▁fragte, ▁sich, ▁dasselbe, .]</td>\n",
       "      <td>[2, 22, 2455, 23, 742, 409, 4, 3]</td>\n",
       "      <td>[2, 28, 1137, 113, 4580, 4, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214296</th>\n",
       "      <td>[▁he, ▁does, ▁not, ▁know, ▁who, ▁built, ▁those...</td>\n",
       "      <td>[▁er, ▁weiß, ▁nicht, ▁wer, ▁die, ▁häuser, ▁dor...</td>\n",
       "      <td>[2, 46, 176, 37, 121, 213, 2124, 863, 3166, 4, 3]</td>\n",
       "      <td>[2, 57, 212, 44, 139, 52, 4221, 548, 3464, 73,...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253252</th>\n",
       "      <td>[▁do, ▁you, ▁know, ▁how, ▁much, ▁strawberries,...</td>\n",
       "      <td>[▁weißt, ▁du, ▁was, ▁die, ▁erdbeeren, ▁jetzt, ...</td>\n",
       "      <td>[2, 35, 21, 121, 153, 303, 3915, 1187, 395, 26...</td>\n",
       "      <td>[2, 818, 51, 106, 52, 5384, 338, 2518, 6, 3]</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               src_tokens  \\\n",
       "125301  [▁that, ▁is, ▁why, ▁i, ▁do, ▁not, ▁like, ▁tom, .]   \n",
       "163846  [▁let, ▁us, ▁start, ▁as, ▁soon, ▁as, ▁he, ▁com...   \n",
       "127910          [▁tom, ▁wondered, ▁the, ▁same, ▁thing, .]   \n",
       "214296  [▁he, ▁does, ▁not, ▁know, ▁who, ▁built, ▁those...   \n",
       "253252  [▁do, ▁you, ▁know, ▁how, ▁much, ▁strawberries,...   \n",
       "\n",
       "                                               trg_tokens  \\\n",
       "125301            [▁deshalb, ▁mag, ▁ich, ▁tom, ▁nicht, .]   \n",
       "163846  [▁lasst, ▁uns, ▁beginnen, ▁sobald, ▁er, ▁kommt...   \n",
       "127910               [▁tom, ▁fragte, ▁sich, ▁dasselbe, .]   \n",
       "214296  [▁er, ▁weiß, ▁nicht, ▁wer, ▁die, ▁häuser, ▁dor...   \n",
       "253252  [▁weißt, ▁du, ▁was, ▁die, ▁erdbeeren, ▁jetzt, ...   \n",
       "\n",
       "                                                  src_ids  \\\n",
       "125301         [2, 56, 32, 193, 8, 35, 37, 133, 22, 4, 3]   \n",
       "163846  [2, 254, 149, 551, 127, 570, 127, 46, 1382, 4, 3]   \n",
       "127910                  [2, 22, 2455, 23, 742, 409, 4, 3]   \n",
       "214296  [2, 46, 176, 37, 121, 213, 2124, 863, 3166, 4, 3]   \n",
       "253252  [2, 35, 21, 121, 153, 303, 3915, 1187, 395, 26...   \n",
       "\n",
       "                                                  trg_ids  src_len  trg_len  \n",
       "125301                   [2, 3252, 403, 27, 28, 44, 4, 3]       11        8  \n",
       "163846          [2, 1410, 166, 3527, 2530, 57, 569, 4, 3]       11        9  \n",
       "127910                     [2, 28, 1137, 113, 4580, 4, 3]        8        7  \n",
       "214296  [2, 57, 212, 44, 139, 52, 4221, 548, 3464, 73,...       11       12  \n",
       "253252       [2, 818, 51, 106, 52, 5384, 338, 2518, 6, 3]       12       10  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2b64d",
   "metadata": {},
   "source": [
    "Saving the cleaned and preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b6ec71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"../data/processed/cleaned_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
