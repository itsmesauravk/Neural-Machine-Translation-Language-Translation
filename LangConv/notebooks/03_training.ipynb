{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b8f75f",
   "metadata": {},
   "source": [
    "GRU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86a85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bcac2",
   "metadata": {},
   "source": [
    "Loading Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5657d531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>trg_tokens</th>\n",
       "      <th>src_ids</th>\n",
       "      <th>trg_ids</th>\n",
       "      <th>src_len</th>\n",
       "      <th>trg_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76253</th>\n",
       "      <td>['▁you', '▁make', '▁a', '▁nice', '▁couple', '.']</td>\n",
       "      <td>['▁ihr', '▁gebt', '▁ein', '▁schönes', '▁paar',...</td>\n",
       "      <td>[2, 21, 390, 9, 864, 1704, 4, 3]</td>\n",
       "      <td>[2, 105, 2961, 41, 2571, 701, 266, 4, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256464</th>\n",
       "      <td>['▁she', '▁was', '▁anxious', '▁to', '▁know', '...</td>\n",
       "      <td>['▁ängstlich', '▁wartete', '▁sie', '▁auf', '▁d...</td>\n",
       "      <td>[2, 148, 74, 3585, 10, 121, 23, 3554, 1150, 26...</td>\n",
       "      <td>[2, 10006, 2580, 54, 94, 52, 9103, 80, 7419, 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               src_tokens  \\\n",
       "76253    ['▁you', '▁make', '▁a', '▁nice', '▁couple', '.']   \n",
       "256464  ['▁she', '▁was', '▁anxious', '▁to', '▁know', '...   \n",
       "\n",
       "                                               trg_tokens  \\\n",
       "76253   ['▁ihr', '▁gebt', '▁ein', '▁schönes', '▁paar',...   \n",
       "256464  ['▁ängstlich', '▁wartete', '▁sie', '▁auf', '▁d...   \n",
       "\n",
       "                                                  src_ids  \\\n",
       "76253                    [2, 21, 390, 9, 864, 1704, 4, 3]   \n",
       "256464  [2, 148, 74, 3585, 10, 121, 23, 3554, 1150, 26...   \n",
       "\n",
       "                                                  trg_ids  src_len  trg_len  \n",
       "76253            [2, 105, 2961, 41, 2571, 701, 266, 4, 3]        8        9  \n",
       "256464  [2, 10006, 2580, 54, 94, 52, 9103, 80, 7419, 4...       12       11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading cleaned dataset\n",
    "df = pd.read_csv(\"../data/processed/cleaned_dataset.csv\")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17058e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277891, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of lists into actual lists\n",
    "import ast\n",
    "df[\"src_ids\"] = df[\"src_ids\"].apply(ast.literal_eval)\n",
    "df[\"trg_ids\"] = df[\"trg_ids\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f72dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbb04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to lists\n",
    "src_data = df[\"src_ids\"].tolist()\n",
    "trg_data = df[\"trg_ids\"].tolist()\n",
    "\n",
    "# Split into train and validation (e.g., 90% train, 10% validation)\n",
    "src_train, src_val, trg_train, trg_val = train_test_split(src_data, trg_data, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88386ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250101, 27790, 250101, 27790)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_train), len(src_val), len(trg_train), len(trg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c3fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b854a9",
   "metadata": {},
   "source": [
    "Creating Datasets and Dataloader using pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef09471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2227119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_data[idx], dtype=torch.long), torch.tensor(self.trg_data[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ee969fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function to pad sequences\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "    return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d025a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = TranslationDataset(src_train, trg_train)\n",
    "val_dataset = TranslationDataset(src_val, trg_val)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d4a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from encoder_rnn import Encoder \n",
    "from decoder_rnn import Decoder\n",
    "from seq2seq_rnn import Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0092f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3dbea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n",
      "90100\n",
      "CUDA available: True\n",
      "Device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4df5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bad8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105aeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for installing PyTorch with CUDA 11.8 support to ensure compatibility with the GPU\n",
    "\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86900566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define parameters\n",
    "INPUT_DIM = 16000   # size of src vocab\n",
    "OUTPUT_DIM = 16000  # size of trg vocab\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "\n",
    "\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HIDDEN_DIM).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # 0 = padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673e7ff",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d373dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for src, trg in progress_bar:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8158943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1350159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a40c88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|▋         | 1/15 [09:32<2:13:32, 572.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 3.7259 | Val Loss: 3.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|█▎        | 2/15 [18:25<1:58:59, 549.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 | Train Loss: 2.5736 | Val Loss: 3.1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 3/15 [31:11<2:09:39, 648.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 | Train Loss: 2.1860 | Val Loss: 3.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  27%|██▋       | 4/15 [44:52<2:11:20, 716.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 | Train Loss: 1.9772 | Val Loss: 2.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 5/15 [1:00:21<2:12:09, 792.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 | Train Loss: 1.8238 | Val Loss: 2.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 6/15 [1:15:06<2:03:39, 824.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 | Train Loss: 1.7200 | Val Loss: 3.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  47%|████▋     | 7/15 [1:28:43<1:49:35, 821.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 | Train Loss: 1.6424 | Val Loss: 3.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|█████▎    | 8/15 [1:40:09<1:30:50, 778.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 | Train Loss: 1.5718 | Val Loss: 3.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 9/15 [1:55:06<1:21:33, 815.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 | Train Loss: 1.5219 | Val Loss: 3.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|██████▋   | 10/15 [2:09:58<1:09:55, 839.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 | Train Loss: 1.4824 | Val Loss: 3.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|███████▎  | 11/15 [2:24:36<56:44, 851.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 | Train Loss: 1.4391 | Val Loss: 3.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 12/15 [2:35:03<39:08, 782.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 | Train Loss: 1.4164 | Val Loss: 3.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  87%|████████▋ | 13/15 [2:44:02<23:37, 708.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 | Train Loss: 1.3853 | Val Loss: 3.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|█████████▎| 14/15 [2:53:33<11:07, 667.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 | Train Loss: 1.3603 | Val Loss: 3.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 15/15 [3:04:32<00:00, 738.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 | Train Loss: 1.3317 | Val Loss: 3.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N_EPOCHS = 15\n",
    "for epoch in trange(N_EPOCHS, desc=\"Epochs\"):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1922a",
   "metadata": {},
   "source": [
    "Model Saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e82c5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'seq2seq_gru_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9ca9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
